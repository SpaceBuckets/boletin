import { prefixStorage } from "unstorage";
import { joinURL, withLeadingSlash } from "ufo";
import { hash as ohash } from "ohash";
import { createQuery } from "../query/query.mjs";
import { createPipelineFetcher } from "../query/match/pipeline.mjs";
import { parseContent } from "./transformers/index.mjs";
import { getPreview, isPreview } from "./preview.mjs";
import { useRuntimeConfig, useStorage } from "#imports";
export const sourceStorage = prefixStorage(useStorage(), "content:source");
export const cacheStorage = prefixStorage(useStorage(), "cache:content");
export const cacheParsedStorage = prefixStorage(useStorage(), "cache:content:parsed");
const isProduction = process.env.NODE_ENV === "production";
const contentConfig = useRuntimeConfig().content;
export const contentIgnores = contentConfig.ignores.map((p) => typeof p === "string" ? new RegExp(`^${p}`) : p);
const contentIgnorePredicate = (key) => !key.startsWith("preview:") && !contentIgnores.some((prefix) => key.split(":").some((k) => prefix.test(k)));
export const getContentsIds = async (event, prefix) => {
  let keys = [];
  if (isProduction) {
    keys = await cacheParsedStorage.getKeys(prefix);
  }
  if (keys.length === 0) {
    keys = await sourceStorage.getKeys(prefix);
  }
  if (isPreview(event)) {
    const { key } = getPreview(event);
    const previewPrefix = `preview:${key}:${prefix || ""}`;
    const previewKeys = await sourceStorage.getKeys(previewPrefix);
    if (previewKeys.length) {
      const keysSet = new Set(keys);
      await Promise.all(previewKeys.map(async (key2) => {
        const meta = await sourceStorage.getMeta(key2);
        if (meta?.__deleted) {
          keysSet.delete(key2.substring(previewPrefix.length));
        } else {
          keysSet.add(key2.substring(previewPrefix.length));
        }
      }));
      keys = Array.from(keysSet);
    }
  }
  return keys.filter(contentIgnorePredicate);
};
export const getContentsList = async (event, prefix) => {
  const keys = await getContentsIds(event, prefix);
  const contents = await Promise.all(keys.map((key) => getContent(event, key)));
  return contents;
};
export const getContent = async (event, id) => {
  const contentId = id;
  if (!contentIgnorePredicate(id)) {
    return { _id: contentId, body: null };
  }
  if (isPreview(event)) {
    const { key } = getPreview(event);
    const previewId = `preview:${key}:${id}`;
    const draft = await sourceStorage.getItem(previewId);
    if (draft) {
      id = previewId;
    }
  }
  const cached = await cacheParsedStorage.getItem(id);
  if (isProduction && cached) {
    return cached.parsed;
  }
  const meta = await sourceStorage.getMeta(id);
  const hash = ohash({
    meta,
    version: contentConfig.cacheVersion,
    integerity: contentConfig.cacheIntegrity
  });
  if (cached?.hash === hash) {
    return cached.parsed;
  }
  const body = await sourceStorage.getItem(id);
  if (body === null) {
    return { _id: contentId, body: null };
  }
  const parsed = await parseContent(contentId, body);
  await cacheParsedStorage.setItem(id, { parsed, hash }).catch(() => {
  });
  return parsed;
};
export function serverQueryContent(event, path, ...pathParts) {
  let params = path || {};
  if (typeof path === "string") {
    path = withLeadingSlash(joinURL(path, ...pathParts));
    path = path.replace(/[-[\]{}()*+.,^$\s]/g, "\\$&");
    params = {
      where: [{ _path: new RegExp(`^${path}`) }]
    };
  }
  const pipelineFetcher = createPipelineFetcher(() => getContentsList(event));
  if (!params.sort?.length) {
    params.sort = [{ _file: 1, $numeric: true }];
  }
  return createQuery(pipelineFetcher, params);
}
